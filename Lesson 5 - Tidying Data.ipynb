{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e06bf0-1657-4184-91ca-e5bf8b7f637f",
   "metadata": {},
   "source": [
    "# Tidying Data in Pandas\n",
    "\n",
    "In this notebook, we will cover various techniques to tidy data using Pandas. Tidy data is crucial for effective data analysis, ensuring that datasets are clean, consistent, and in a format ready for analysis. We will work through several common data wrangling tasks, including handling datetime objects, string manipulation, reshaping data, merging datasets, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3c40a-0bad-4cc9-88a9-e612204ad86d",
   "metadata": {},
   "source": [
    "# Handling Date Time Data in Pandas\n",
    "\n",
    "## Introduction\n",
    "Date and time data are critical components in data analysis, especially when working with time series data or any dataset where the timing of events is important. However, date formats can vary widely depending on geographic location, data entry methods, or file formats, leading to challenges in consistent data processing.\n",
    "\n",
    "### Common Date Formats\n",
    "Some common date formats include:\n",
    "- `YYYY-MM-DD` (e.g., 2021-07-23) - ISO 8601 standard, widely used internationally.\n",
    "- `MM/DD/YYYY` (e.g., 07/23/2021) - Common in the United States.\n",
    "- `DD/MM/YYYY` (e.g., 23/07/2021) - Common in the United Kingdom and other countries.\n",
    "\n",
    "## Handling Mixed Date Formats\n",
    "When working with datasets that include mixed date formats (e.g., some entries in `YYYY-MM-DD` and others in `DD/MM/YYYY`), it's essential to standardise the dates for consistent analysis.\n",
    "\n",
    "### Using `format='mixed'` in Pandas\n",
    "Pandas provides a `format='mixed'` option in the `pd.to_datetime()` function that allows the library to infer the format for each date individually. This is useful when you cannot predict the format or the dataset is highly inconsistent..\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2212abfc-e591-4b59-80a0-0ba1388c1bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Event_Date  Year  Month  Day\n",
      "0   1 2021-07-23  2021      7   23\n",
      "1   2 2021-08-01  2021      8    1\n",
      "2   3 2021-07-23  2021      7   23\n",
      "3   4 2021-01-08  2021      1    8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with different date formats\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Event_Date': ['2021-07-23', '2021/08/01', '23-07-2021', '01-08-2021']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Converting string dates to datetime objects using mixed format\n",
    "df['Event_Date'] = pd.to_datetime(df['Event_Date'], format='mixed')\n",
    "\n",
    "# Extracting components\n",
    "df['Year'] = df['Event_Date'].dt.year\n",
    "df['Month'] = df['Event_Date'].dt.month\n",
    "df['Day'] = df['Event_Date'].dt.day\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75ab03-8d0d-475f-b592-9585461b0f4d",
   "metadata": {},
   "source": [
    "## String Splitting and Normalisation\n",
    "\n",
    "Text data often needs cleaning and normalisation. We'll cover how to split strings into multiple columns and normalise inconsistent text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1d8d312-b1b7-466f-8e8e-8977777dd8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Full_Name                    Email First_Name Last_Name\n",
      "0    john doe     john.doe@example.com       john       doe\n",
      "1  jane smith   jane.smith@example.com       jane     smith\n",
      "2    john doe    john.doe2@example.com       john       doe\n",
      "3  jane smith  jane.smith2@example.com       jane     smith\n"
     ]
    }
   ],
   "source": [
    "# Sample data with inconsistent formats\n",
    "data = {\n",
    "    'Full_Name': ['John Doe', 'Jane Smith', 'john doe', 'JANE SMITH'],\n",
    "    'Email': ['john.doe@example.com', 'jane.smith@example.com', 'john.doe2@example.com', 'jane.smith2@example.com']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize names by lowercasing\n",
    "df['Full_Name'] = df['Full_Name'].str.lower()\n",
    "\n",
    "# Splitting full names into first and last names\n",
    "df[['First_Name', 'Last_Name']] = df['Full_Name'].str.split(' ', expand=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020bd4b0-4089-4bc7-a935-dd4efac37fee",
   "metadata": {},
   "source": [
    "## Merging DataFrames\n",
    "\n",
    "Sometimes you need to combine data from multiple DataFrames. We'll explore how to merge data on specific keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "042922f1-b9db-4897-97ca-bd07380666d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "   ID  Name   Age\n",
      "0   1  John  28.0\n",
      "1   2  Jane  34.0\n",
      "2   3   Jim   NaN\n"
     ]
    }
   ],
   "source": [
    "# Sample data for merging\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['John', 'Jane', 'Jim']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [1, 2, 4],\n",
    "    'Age': [28, 34, 29]\n",
    "})\n",
    "\n",
    "# Merging DataFrames on 'ID'\n",
    "merged_df = pd.merge(df1, df2, on='ID', how='left')\n",
    "\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ae0cd-bd27-4614-be66-fc1376123755",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "\n",
    "Filtering data is an essential skill for isolating relevant subsets of data based on specific criteria. We'll cover how to filter rows using conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de491212-d3ec-47ae-9b43-d9637411c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame (Age > 30):\n",
      "   ID  Name   Age\n",
      "1   2  Jane  34.0\n"
     ]
    }
   ],
   "source": [
    "# Filtering rows where Age is greater than 30\n",
    "filtered_df = merged_df[merged_df['Age'] > 30]\n",
    "\n",
    "print(\"Filtered DataFrame (Age > 30):\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84260685-9cc1-49fc-a90f-f1cf8d43f036",
   "metadata": {},
   "source": [
    "## Applying Functions with `apply` and `map`\n",
    "\n",
    "Pandas allows you to apply custom functions to your data. We'll use `apply` for row-wise or column-wise operations and `map` for element-wise transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37317773-5cd8-4d3c-87f6-c8a58721cb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after applying function to increase scores:\n",
      "   Name  Score  Increased_Score\n",
      "0  John     85            89.25\n",
      "1  Jane     90            94.50\n",
      "2   Jim     88            92.40\n",
      "\n",
      "DataFrame after mapping grades based on score ranges:\n",
      "   Name  Score  Increased_Score Grade (ranged) Grade (mapped)\n",
      "0  John     85            89.25              B              B\n",
      "1  Jane     90            94.50              A              A\n",
      "2   Jim     88            92.40              B             B+\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John', 'Jane', 'Jim'],\n",
    "    'Score': [85, 90, 88]\n",
    "})\n",
    "\n",
    "# Define a function to increase scores by 5%\n",
    "def increase_score(score):\n",
    "    return score * 1.05\n",
    "\n",
    "# Applying the custom function to increase scores\n",
    "df['Increased_Score'] = df['Score'].apply(increase_score)\n",
    "\n",
    "print(\"DataFrame after applying function to increase scores:\")\n",
    "print(df)\n",
    "\n",
    "# Define a function to map scores to grades based on ranges\n",
    "def map_grade(score):\n",
    "    if 90 <= score <= 100:\n",
    "        return 'A'\n",
    "    elif 80 <= score < 90:\n",
    "        return 'B'\n",
    "    elif 70 <= score < 80:\n",
    "        return 'C'\n",
    "    elif 60 <= score < 70:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Apply the function to map grades\n",
    "df['Grade (ranged)'] = df['Score'].apply(map_grade)\n",
    "\n",
    "# Mapping a dictionary to replace values\n",
    "grade_mapping = {85: 'B', 90: 'A', 88: 'B+'}\n",
    "df['Grade (mapped)'] = df['Score'].map(grade_mapping)\n",
    "\n",
    "print(\"\\nDataFrame after mapping grades based on score ranges:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bd7f0-7f60-4231-9f23-ccf360f53e3f",
   "metadata": {},
   "source": [
    "# Restaurant Data Analysis Challenges\n",
    "\n",
    "## Standard Challenges:\n",
    "\n",
    "### 1. Merge the Datasets\n",
    "**Challenge:** \n",
    "- Merge the `user_ratings.csv` dataset with the `restaurants.csv` dataset based on `placeID`.\n",
    "- Ensure that all columns from both datasets are included in the final DataFrame.\n",
    "\n",
    "### 2. Tidy the Data and Deal with Missing Values\n",
    "**Challenge:** \n",
    "- Normalise the DateTime to be the `ISO 8601` standard\n",
    "- Standardize the `city` column to ensure it matches one of the following formats only: \"Ciudad Victoria,\" \"Cuernavaca,\" \"Jiutepec,\" \"San Luis Potosi,\" or \"Soledad.\" \n",
    "- Fill in missing `zip` codes using other available information (such as `state` and `city`).\n",
    "- Handle any other missing values by filling them with the mode for categorical data and the mean for numeric data.\n",
    "\n",
    "### 3. Calculate Average Ratings\n",
    "**Challenge:** \n",
    "- For each restaurant (`placeID`), calculate the average `food_rating`, `service_rating`, and overall `rating`.\n",
    "- Create a new DataFrame with these average ratings.\n",
    "\n",
    "### 4. Identify Top-Rated Restaurants\n",
    "**Challenge:** \n",
    "- Using the average ratings calculated in the previous challenge, identify the top 5 restaurants.\n",
    "- Display their `placeID`, `name`, `city`, and average ratings.\n",
    "\n",
    "### 5. Filter Restaurants by Accessibility\n",
    "**Challenge:** \n",
    "- Filter the merged DataFrame to find all restaurants that are fully accessible (`accessibility` column is \"completely\").\n",
    "- Display the `placeID`, `name`, and average rating for these restaurants.\n",
    "\n",
    "### 6. Payment Method Preferences\n",
    "**Challenge:** \n",
    "- Merge the `user_payment.csv` dataset with the `user_ratings.csv` dataset on `userID`.\n",
    "- Determine which payment method is most frequently used by users who rate restaurants with a `rating` of 4 or higher.\n",
    "\n",
    "### 7. Restaurant Availability in Different Cities\n",
    "**Challenge:** \n",
    "- Group the merged DataFrame by `city` and count how many restaurants are available in each city.\n",
    "- Display the `city` and the corresponding restaurant count.\n",
    "\n",
    "## Bonus Challenges\n",
    "\n",
    "### Bonus Challenge 1\n",
    "Using the rating column, categorise each restaurant into different rating categories:\n",
    "\n",
    "- \"Low\" for ratings between 1 and 2.\n",
    "- \"Medium\" for ratings between 3 and 4.\n",
    "- \"High\" for ratings of 5.\n",
    "\n",
    "### Bonus Challenge 2\n",
    "Create a new column called `Quality_Score` that combines both `food_rating` and `service_rating` to provide an overall score for each restaurant. The Quality_Score should be calculated as the weighted average of the `food_rating` and `service_rating`, where `food_rating` is given a weight of 0.7 and `service_rating` is given a weight of 0.3. Use the `.apply()` function to compute this new score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
